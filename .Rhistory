.normalised <- log2(.counts+1)
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': transformation completed\n')))
}
dec <- scran::modelGeneVar(x = .normalised)
.highly.variable.genes <- scran::getTopHVGs(stats = dec, n=n.genes)
seuobj <- Seurat::CreateSeuratObject(counts = mat)
seuobj@assays$RNA@data <- .normalised[.highly.variable.genes,]
if(!is.null(vars.to.regress)) {
vars.to.regress.df <- as.data.frame(object@sample_metadata[,vars.to.regress])
colnames(vars.to.regress.df) <- vars.to.regress
rownames(vars.to.regress.df) <- colnames(object)
vars.to.regress.df <- vars.to.regress.df[match(rownames(seuobj@meta.data),
rownames(vars.to.regress.df)),]
seuobj@meta.data <- cbind(seuobj@meta.data,vars.to.regress.df)
colnames(seuobj@meta.data) <- c(names(seuobj@meta.data)[1:sum(length(names(seuobj@meta.data))-length(vars.to.regress))], vars.to.regress)
seuobj <- Seurat::ScaleData(object = seuobj, do.scale=do.scale, do.center=do.center,vars.to.regress=vars.to.regress, verbose = verbose, ...)
} else {
seuobj <- Seurat::ScaleData(object = seuobj, do.scale=do.scale, do.center=do.center, verbose = verbose, ...)
}
.norm.scaled <- seuobj@assays$RNA@scale.data
feat.meta <- feature_metadata(assay = .counts, col.prefix = paste0('SCRAN', new.assay.suffix))
object@sample_metadata <- cbind(object@sample_metadata, cell_metadata(assay = as.matrix(.normalised), col.prefix = paste0('TPM', new.assay.suffix)))
object@methods[[paste0('TPM', new.assay.suffix)]] <- new(Class = 'methods',
counts = Matrix::Matrix(.counts, sparse = T),
normalised = Matrix::Matrix(.normalised, sparse = T),
norm.scaled = as.matrix(.norm.scaled),
highly.variable.genes = .highly.variable.genes,
feature_metadata = feat.meta)
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': TPM normalisation completed\n')))
}
end_time <- Sys.time()
function_time <- end_time - start_time
if(!'normalisation_method' %in% colnames(object@pipelines)) {
object@pipelines <- data.frame(normalisation_method=paste0('TPM', new.assay.suffix), normalisation_time=function_time)
} else if (paste0('TPM', new.assay.suffix) %in% object@pipelines[,'normalisation_method']) {
object@pipelines[which(object@pipelines[,'normalisation_method']==paste0('TPM', new.assay.suffix)),] <- data.frame(normalisation_method=paste0('TPM', new.assay.suffix), normalisation_time=function_time)
} else {
object@pipelines <- rbind(object@pipelines, data.frame(normalisation_method=paste0('TPM', new.assay.suffix), normalisation_time=function_time))
}
return(object)
}
#' @name perform.tpm
#' @aliases perform.tpm
#'
#' @title Performs TPM normalisation
#'
#' @description Performs TPM normalisation, scran hvg selection, scaling and variance stabilisation and regression.
#'
#' @param object IBRAP S4 class object
#' @param assay Character. String containing indicating which assay to use
#' @param slot Character. String indicating which slot within the assay should be sourced
#' @param n.genes Numerical. Top number of genes to retain when finding HVGs. Default = 1500
#' @param do.scale Boolean. Whether to scale the features variance. Default = TRUE
#' @param do.centre Boolean. Whether to centre features to zero. Default = TRUE
#' @param vars.to.regress Character. Which column in the metadata should be regressed. Default = NULL
#' @param new.assay.suffix Character. What should the new assay be called. Default = 'SCRAN'
#' @param verbose Logical Should function messages be printed?
#' @param ... Arguments to pass to Seurat::ScaleData
#'
#' @return Produces a new 'methods' assay containing normalised, scaled and HVGs.
#'
#' @examples
#'
#' object <- perform.scanpy(object = object,
#'                          vars.to.regress = 'RAW_total.counts', do.scale = T)
#'
#' @export
perform.tpm <- function(object,
assay = 'RAW',
slot = 'counts',
n.genes = 1500,
do.scale = FALSE,
do.center = TRUE,
vars.to.regress = NULL,
new.assay.suffix = '',
verbose = FALSE,
...) {
if(!is(object = object, class2 = 'IBRAP')) {
stop('object must be of class IBRAP\n')
}
if(!is.logical(verbose)) {
stop('verbose must be logical, TRUE/FALSE\n')
}
if(!is.character(assay)) {
stop('assay must be a character string\n')
}
if(!assay %in% names(object@methods)) {
stop('assay does not exist\n')
}
if(!is.character(slot)) {
stop('slot must be a character string\n')
}
if(!slot %in% c('counts', 'normalised', 'norm.scaled')) {
stop('slot does not exist\n')
}
if(!is.numeric(n.genes)) {
stop('n.genes must be numerical\n')
}
r <- read.table(text = as.character(IBRAP::mart_export$Gene.stable.ID.Gene.name.Gene.start..bp..Gene.end..bp.), sep = ',')
colnames(r) <- c('geneID', 'geneName', 'start', 'end')
if(is.null(r)) {
stop('cannot find gene lengths\n')
}
if(!is.logical(do.scale)) {
stop('do.scale must be logical: TRUE/FALSE\n')
}
if(!is.logical(do.center)) {
stop('do.center must be logical: TRUE/FALSE\n')
}
if(!is.null(vars.to.regress)) {
if(!is.character(vars.to.regress)) {
stop('vars.to.regress must be character string\n')
}
}
if(!is.character(new.assay.suffix)) {
stop('new.assay.suffix must be a character string\n')
}
if('_' %in% unlist(strsplit(x = new.assay.suffix, split = ''))) {
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': _ cannot be used in new.assay.suffix, replacing with - \n')))
}
new.assay.suffix <- sub(pattern = '_', replacement = '-', x = new.assay.suffix)
}
start_time <- Sys.time()
r$Gene.length <- r$end - r$start
subset <- r[r$geneName %in% rownames(object),]
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': matrix subsetted\n')))
}
rownames(subset) <- make.unique(names = as.character(subset$geneName), '.')
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': rownames added\n')))
}
meta <- object@methods[[assay]]@feature_metadata[intersect(rownames((object@methods[[assay]]@feature_metadata)), rownames(subset)),]
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': gene names interesected\n')))
}
mat <- as.matrix(object@methods[[assay]][[slot]])
mat <- mat[intersect(rownames(mat), rownames(subset)),]
ordered <- subset[match(rownames(mat), rownames(subset)),]
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': matrices ordered\n')))
cat(crayon::cyan(paste0(Sys.time(), ': calculated counts/feature length\n')))
}
calc <- sweep(mat, 1, as.numeric(ordered$Gene.length), `/`)
scale.factor <- colSums(calc)/1000000
.counts <- sweep(calc, 2, as.numeric(scale.factor), `/`)
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': calculations completed\n')))
}
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': log2(x+1) transforming\n')))
}
.normalised <- log2(.counts+1)
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': transformation completed\n')))
}
dec <- scran::modelGeneVar(x = .normalised)
.highly.variable.genes <- scran::getTopHVGs(stats = dec, n=n.genes)
seuobj <- suppressWarnings(Seurat::CreateSeuratObject(counts = mat))
seuobj@assays$RNA@data <- .normalised[.highly.variable.genes,]
if(!is.null(vars.to.regress)) {
vars.to.regress.df <- as.data.frame(object@sample_metadata[,vars.to.regress])
colnames(vars.to.regress.df) <- vars.to.regress
rownames(vars.to.regress.df) <- colnames(object)
vars.to.regress.df <- vars.to.regress.df[match(rownames(seuobj@meta.data),
rownames(vars.to.regress.df)),]
seuobj@meta.data <- cbind(seuobj@meta.data,vars.to.regress.df)
colnames(seuobj@meta.data) <- c(names(seuobj@meta.data)[1:sum(length(names(seuobj@meta.data))-length(vars.to.regress))], vars.to.regress)
seuobj <- Seurat::ScaleData(object = seuobj, do.scale=do.scale, do.center=do.center,vars.to.regress=vars.to.regress, verbose = verbose, ...)
} else {
seuobj <- Seurat::ScaleData(object = seuobj, do.scale=do.scale, do.center=do.center, verbose = verbose, ...)
}
.norm.scaled <- seuobj@assays$RNA@scale.data
feat.meta <- feature_metadata(assay = .counts, col.prefix = paste0('SCRAN', new.assay.suffix))
object@sample_metadata <- cbind(object@sample_metadata, cell_metadata(assay = as.matrix(.normalised), col.prefix = paste0('TPM', new.assay.suffix)))
object@methods[[paste0('TPM', new.assay.suffix)]] <- new(Class = 'methods',
counts = Matrix::Matrix(.counts, sparse = T),
normalised = Matrix::Matrix(.normalised, sparse = T),
norm.scaled = as.matrix(.norm.scaled),
highly.variable.genes = .highly.variable.genes,
feature_metadata = feat.meta)
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': TPM normalisation completed\n')))
}
end_time <- Sys.time()
function_time <- end_time - start_time
if(!'normalisation_method' %in% colnames(object@pipelines)) {
object@pipelines <- data.frame(normalisation_method=paste0('TPM', new.assay.suffix), normalisation_time=function_time)
} else if (paste0('TPM', new.assay.suffix) %in% object@pipelines[,'normalisation_method']) {
object@pipelines[which(object@pipelines[,'normalisation_method']==paste0('TPM', new.assay.suffix)),] <- data.frame(normalisation_method=paste0('TPM', new.assay.suffix), normalisation_time=function_time)
} else {
object@pipelines <- rbind(object@pipelines, data.frame(normalisation_method=paste0('TPM', new.assay.suffix), normalisation_time=function_time))
}
return(object)
}
tmp <- perform.tpm(object = smartseq2, vars.to.regress = 'RAW_total.counts', verbose = T)
tmp <- perform.tpm(object = smartseq2, vars.to.regress = 'RAW_total.counts')
smartseq2 <- perform.tpm(object = smartseq2, vars.to.regress = 'RAW_total.counts', verbose = T)
smartseq2 <- perform.tpm(object = smartseq2, vars.to.regress = 'RAW_total.counts')
BiocManager::install(c('BiocGenerics', 'DelayedArray', 'DelayedMatrixStats',
'limma', 'S4Vectors', 'SingleCellExperiment',
'SummarizedExperiment', 'batchelor', 'Matrix.utils'))BiocManager::install(c('BiocGenerics', 'DelayedArray', 'DelayedMatrixStats',
'limma', 'S4Vectors', 'SingleCellExperiment',
'SummarizedExperiment', 'batchelor', 'Matrix.utils'))
BiocManager::install(c('BiocGenerics', 'DelayedArray', 'DelayedMatrixStats',
'limma', 'S4Vectors', 'SingleCellExperiment',
'SummarizedExperiment', 'batchelor', 'Matrix.utils'))
install.packages("renv")
ls()
pre_seurat_integrated <- readRDS("~/work/Results/scRNA-seq/pre_seurat_integrated.rds")
library(IBRAP)
#' @name perform.scanorama
#' @aliases perform.scanorama
#'
#' @title Performs Scanorama integration
#'
#' @description Performs Scanorama integration on defined method-assays and reductions contained within. This is performed on reductions.
#'
#' @param object IBRAP S4 class object
#' @param assay Character. String containing indicating which assay to use
#' @param slot Character. String defining which slot in the assay to supply to Scanorama. Default = NULL
#' @param batch Character. indicating the metadata column containing the batch to split the assay by.
#' @param n.dims Numerical. The number of Scanorama dimensions to be produced. Default = 50
#' @param reduction.save.suffix Character. Should a suffix be added to the end of scanorama, This cannot include underscores.
#' @param batch_size Numerical. The batch size used in the alignment vector computation. Useful when integrating large datasets. Default = 5000
#' @param approx Boolean. Use appoximate nearest neighbours within python, speeds up runtime. Default = TRUE
#' @param sigma Numerical. Correction smoothing parameter on Gaussian kernel. Default = 15
#' @param alpha Numerical. Alignment score minimum cutoff. Default = 0.1
#' @param knn Numerical. Number of nearest neighbors to use for matching. Default = 20
#' @param verbose Logical Should function messages be printed?
#' @param seed Numerical What seed should be set. Default = 1234
#'
#' @return Scanorama reduction saved in the supplied method-assays
#'
#' @examples
#'
#' object <- perform.scanorama(object = object,
#'                             assay = c('SCT', 'SCRAN', 'SCANPY'),
#'                             slot = 'norm.scaled',
#'                             batch = 'original.project',
#'                             n.dims = 50)
#'
#' @export
perform.scanorama <- function(object,
assay,
slot = 'norm.scaled',
batch,
n.dims = 50,
reduction.save.suffix='',
batch_size = 5000,
approx = TRUE,
sigma = 15,
alpha = 0.1,
knn = 20,
union = FALSE,
verbose = FALSE,
seed=1234) {
if(!is(object = object, class2 = 'IBRAP')) {
stop('object must be of class IBRAP \n')
}
if(!is.character(assay)) {
stop('assay must be character string\n')
}
for(x in assay) {
if(!x %in% names(object@methods)) {
stop(paste0('reduction: ', x, 'does not exist\n'))
}
}
if(!is.character(slot)) {
stop('slot must be a character string\n')
}
if(!slot %in% c('counts', 'normalised', 'norm.scaled')) {
stop('slot does not exist\n')
}
if(!is.character(batch)) {
stop('batch must be character string\n')
} else if(is.character(batch)) {
for(x in batch) {
if(!x %in% names(object@sample_metadata)) {
stop(paste0(x, ' is not contained within object@sample_metadata'))
}
}
}
if(is.null(n.dims)) {
n.dims <- list()
for(x in 1:length(reduction))  {
n.dims[[x]] <- 0
}
} else if(!is.numeric(n.dims)) {
stop('n.dims must be numerical\n')
}
if(!is.character(reduction.save.suffix)) {
stop('reduction.save.suffix must be character string\n')
}
if(!is.numeric(batch_size)) {
stop('batch_size must be numerical\n')
}
if(!is.logical(approx)) {
stop('approx must be logical: TRUE/FALSE\n')
}
if(!is.numeric(sigma)) {
stop('sigma must be numerical\n')
}
if(!is.numeric(alpha)) {
stop('alpha must be numerical\n')
}
if(!is.numeric(knn)) {
stop('knn must be numerical\n')
}
if(!is.logical(union)) {
stop('union must be logical: TRUE/FALSE\n')
}
if(!is.logical(verbose)) {
stop('verbose should be logical, TRUE/FALSE \n')
}
if(!is.numeric(seed)) {
stop('seed must be a numerical value \n')
}
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': loading python modules\n')))
}
scanorama <- reticulate::import('scanorama', convert = FALSE)
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': python modules loaded\n')))
}
temp <- function(x) {
return(paste(x, collapse = '_'))
}
count <- 1
set.seed(seed = seed, kind = "Mersenne-Twister", normal.kind = "Inversion")
reticulate::py_set_seed(seed, disable_hash_randomization = TRUE)
if(!'integration_method' %in% colnames(object@pipelines)) {
tmp <- tibble::add_column(.data = object@pipelines, integration_method=NA, integration_time=NA)
} else {
tmp <- object@pipelines
}
for(p in assay) {
start_time <- Sys.time()
if(length(batch) > 1) {
df <- object@sample_metadata[,batch]
df <- as.data.frame(apply(X = df, MARGIN = 1, FUN = temp))
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': initialising scanorama for assay: ', p, '\n')))
}
list.matrix <- list()
column.names <- list()
sep <- unique(df[,1])
mat <- object@methods[[p]][[slot]]
counter <- 1
for(x in sep) {
column.names[[counter]] <- colnames(mat[,df[,1] == x])
list.matrix[[counter]] <- t(mat[,df[,1] == x])
counter <- counter + 1
}
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': matrices isolated\n')))
}
gene.list <- list()
for(x in 1:length(sep)) {
gene.list[[x]] <- rownames(mat[,df[,1] == x])
}
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': genes identified\n')))
cat(crayon::cyan(paste0(Sys.time(), ': corrections starting\n')))
}
} else {
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': initialising scanorama for assay: ', p, '\n')))
}
list.matrix <- list()
column.names <- list()
sep <- unique(object@sample_metadata[,batch])
mat <- object@methods[[p]][[slot]]
counter <- 1
for(x in sep) {
column.names[[counter]] <- colnames(mat[,object@sample_metadata[,batch] == x])
list.matrix[[counter]] <- t(mat[,object@sample_metadata[,batch] == x])
counter <- counter + 1
}
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': matrices isolated\n')))
}
gene.list <- list()
for(x in 1:length(sep)) {
gene.list[[x]] <- rownames(mat[,object@sample_metadata[,batch] == x])
}
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': genes identified\n')))
cat(crayon::cyan(paste0(Sys.time(), ': corrections starting\n')))
}
}
if(isTRUE(verbose)) {
integrated.corrected.data <- scanorama$correct(datasets_full = reticulate::r_to_py(list.matrix),
genes_list = reticulate::r_to_py(gene.list),
dimred = as.integer(n.dims),
return_dimred=TRUE,
return_dense=FALSE,
verbose = TRUE,
batch_size = as.integer(batch_size),
approx = approx,
sigma = as.integer(sigma),
alpha = as.numeric(alpha),
knn = as.integer(knn),
union = as.logical(union),
seed = as.integer(seed))
}
if(isFALSE(verbose)) {
integrated.corrected.data <- scanorama$correct(datasets_full = reticulate::r_to_py(list.matrix),
genes_list = reticulate::r_to_py(gene.list),
dimred = as.integer(n.dims),
return_dimred=TRUE,
return_dense=FALSE,
verbose = FALSE,
batch_size = as.integer(batch_size),
approx = approx,
sigma = as.integer(sigma),
alpha = as.numeric(alpha),
knn = as.integer(knn),
union = as.logical(union),
seed = as.integer(seed))
}
dims <- list()
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': isolating scanorama reduced dimensions\n')))
}
dim.names <- list()
for(c in 1:n.dims) {
dim.names[[c]] <- paste0('scanorama_', c)
}
dim.names <- unlist(dim.names)
for(x in 1:length(sep)) {
transposed <- t(reticulate::py_to_r(integrated.corrected.data)[[1]][[x]])
colnames(transposed) <- column.names[[x]]
rownames(transposed) <- dim.names
dims[[x]] <- transposed
}
if('_' %in% unlist(strsplit(x = reduction.save.suffix, split = ''))) {
reduction.save.suffix <- sub(pattern = '_', replacement = '-', x = reduction.save.suffix)
}
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': combining samples\n')))
}
combined <- do.call('cbind', dims)
if(isTRUE(verbose)) {
cat(crayon::cyan(paste0(Sys.time(), ': samples concatenated\n')))
}
object@methods[[p]]@integration_reductions[[paste0('SCANORAMA', reduction.save.suffix)]] <- t(combined)
end_time <- Sys.time()
function_time <- end_time - start_time
if(!'integration_method' %in% colnames(object@pipelines)) {
tmp[which(x = tmp$normalisation_method==p),'integration_method'] <- paste0('SCANORAMA', reduction.save.suffix)
tmp[which(x = tmp$normalisation_method==p),'integration_time'] <- as.difftime(function_time, units = 'secs')
}
if('integration_method' %in% colnames(object@pipelines)) {
if(paste0('SCANORAMA', reduction.save.suffix) %in% tmp$integration_method) {
tmp[which(tmp$normalisation_method==p & tmp$integration_method==paste0('SCANORAMA', reduction.save.suffix)),] <- c(tmp[which(tmp$normalisation_method==p & tmp$integration_method==paste0('SCANORAMA', reduction.save.suffix)),c('normalisation_method','normalisation_time')], paste0('SCANORAMA', reduction.save.suffix), as.difftime(function_time, units = 'secs'))
}
if(!paste0('SCANORAMA', reduction.save.suffix) %in% object@pipelines$integration_method) {
df <- tmp[which(tmp$normalisation_method==p),]
df <- df[!duplicated(df$normalisation_method),]
df[,'integration_method'] <- paste0('SCANORAMA', reduction.save.suffix)
df[,'integration_time'] <- function_time
tmp <- rbind(tmp, df)
}
}
}
tmp$integration_time <- as.difftime(tim = tmp$integration_time, units = 'secs')
rownames(tmp) <- 1:nrow(tmp)
object@pipelines <- tmp
return(object)
}
setwd("~/Documents/GitHub/IBRAP")
roxygen2::roxygenise()
rm(perform.scanorama)
roxygen2::roxygenise()
pkgdown::build_articles()
pkgdown::build_articles()
pkgdown::build_articles()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(IBRAP)
options(future.globals.maxSize = 12000 * 1024^2)
celseq2_items <- readRDS('~/Documents/GitHub/IBRAP/data/celseq2.rds')
smartseq2_items <- readRDS('~/Documents/GitHub/IBRAP/data/smartseq2.rds')
celseq2 <- createIBRAPobject(counts = celseq2_items$counts,
meta.data = celseq2_items$metadata,
original.project = 'celseq2',
min.cells = 3,
min.features = 200)
smartseq2 <- createIBRAPobject(counts = smartseq2_items$counts,
meta.data = smartseq2_items$metadata,
original.project = 'smartseq2',
min.cells = 3,
min.features = 200)
pancreas <- merge(x = celseq2, y = smartseq2)
pancreas <- perform.sct(object = pancreas,
assay = 'RAW',
slot = 'counts')
pancreas <- perform.scran(object = pancreas,
assay = 'RAW',
slot = 'counts',
vars.to.regress = 'RAW_total.counts')
pancreas <- perform.scanpy(object = pancreas,
vars.to.regress = 'RAW_total.counts')
pkgdown::build_articles()
rlang::last_error()
plot.variance(object = pancreas, assay = c('SCT', 'SCRAN', 'SCANPY'), reduction = 'PCA')
